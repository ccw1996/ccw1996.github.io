"use strict";(self.webpackChunkblog_sample=self.webpackChunkblog_sample||[]).push([[7626],{8453:(e,t,n)=>{n.d(t,{R:()=>s,x:()=>a});var i=n(6540);const r={},o=i.createContext(r);function s(e){const t=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),i.createElement(o.Provider,{value:t},e.children)}},9212:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>a,default:()=>m,frontMatter:()=>s,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"ml/llm_convert_trick","title":"\u8d85\u5927\u6a21\u578b\u52a0\u8f7d\u8f6c\u6362Trick","description":"\u5728\u8fd9\u6bb5\u4ee3\u7801\u7684\u4e2d, mymodel = BigModelClass(...) \u4f1a\u521d\u59cb\u5316\u4e00\u4e2a\u6a21\u578b, torch.load(checkpointfile)\u51fd\u6570\u4f1a\u5c06\u6a21\u578b\u6743\u91cd\u4ece\u78c1\u76d8\u52a0\u8f7d\u5230\u5185\u5b58\u4e2d\u3002\u7136\u540e\uff0cmymodel.loadstatedict(statedict)\u51fd\u6570\u4f1a\u5c06\u6743\u91cd\u4ece\u5185\u5b58\u52a0\u8f7d\u5230\u6a21\u578b\u7684\u53c2\u6570\u4e2d\u3002\u8fd9\u4e24\u4e2a\u6b65\u9aa4\u90fd\u53ef\u80fd\u4f1a\u6d88\u8017\u5927\u91cf\u7684\u65f6\u95f4\u548c\u5185\u5b58\u3002\u7406\u60f3\u60c5\u51b5\u4e0b, \u4e00\u4e2a236B BF16\u683c\u5f0f\u7684\u6a21\u578b\u9700\u8981\u5360\u636e 472GB \u7684\u5185\u5b58, \u4e0a\u9762\u7684\u4ee3\u7801\u4f1a\u6709\u4e24\u4e2a\u6a21\u578b\u526f\u672c, \u8fd9\u610f\u5473\u7740\u5cf0\u503c\u9700\u8981944GB \u5185\u5b58, \u63a5\u8fd11T ,\u8fd9\u662f\u975e\u5e38\u5938\u5f20\u7684\u4e5f\u662f\u4e0d\u53ef\u63a5\u53d7\u7684.","source":"@site/docs/ml/llm_convert_trick.md","sourceDirName":"ml","slug":"/ml/llm_convert_trick","permalink":"/docs/ml/llm_convert_trick","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/edit/main/website/docs/ml/llm_convert_trick.md","tags":[{"inline":true,"label":"machine learning","permalink":"/docs/tags/machine-learning"},{"inline":true,"label":"interview","permalink":"/docs/tags/interview"}],"version":"current","lastUpdatedAt":1740785860000,"frontMatter":{"title":"\u8d85\u5927\u6a21\u578b\u52a0\u8f7d\u8f6c\u6362Trick","tags":["machine learning","interview"]},"sidebar":"tutorialSidebar","previous":{"title":"\u7b97\u6cd5\u5de5\u7a0b\u5e08\u9762\u7ecf","permalink":"/docs/ml/interview"},"next":{"title":"onnx\u64cd\u4f5c","permalink":"/docs/ml/onnx"}}');var r=n(4848),o=n(8453);const s={title:"\u8d85\u5927\u6a21\u578b\u52a0\u8f7d\u8f6c\u6362Trick",tags:["machine learning","interview"]},a="\u95ee\u9898\u5206\u6790",d={},l=[{value:"\u4f7f\u7528<code>torch.load(mmap=True)</code>",id:"\u4f7f\u7528torchloadmmaptrue",level:2},{value:"\u4f7f\u7528 <code>torch.device(&#39;meta&#39;)</code>",id:"\u4f7f\u7528-torchdevicemeta",level:2}];function c(e){const t={blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"\u95ee\u9898\u5206\u6790",children:"\u95ee\u9898\u5206\u6790"})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:"import torch\n\nstate_dict = torch.load(checkpoint_file)\nmy_model = BigModelClass(...)\nmy_model.load_state_dict(state_dict)\n"})}),"\n",(0,r.jsx)(t.p,{children:"\u5728\u8fd9\u6bb5\u4ee3\u7801\u7684\u4e2d, my_model = BigModelClass(...) \u4f1a\u521d\u59cb\u5316\u4e00\u4e2a\u6a21\u578b, torch.load(checkpoint_file)\u51fd\u6570\u4f1a\u5c06\u6a21\u578b\u6743\u91cd\u4ece\u78c1\u76d8\u52a0\u8f7d\u5230\u5185\u5b58\u4e2d\u3002\u7136\u540e\uff0cmy_model.load_state_dict(state_dict)\u51fd\u6570\u4f1a\u5c06\u6743\u91cd\u4ece\u5185\u5b58\u52a0\u8f7d\u5230\u6a21\u578b\u7684\u53c2\u6570\u4e2d\u3002\u8fd9\u4e24\u4e2a\u6b65\u9aa4\u90fd\u53ef\u80fd\u4f1a\u6d88\u8017\u5927\u91cf\u7684\u65f6\u95f4\u548c\u5185\u5b58\u3002\u7406\u60f3\u60c5\u51b5\u4e0b, \u4e00\u4e2a236B BF16\u683c\u5f0f\u7684\u6a21\u578b\u9700\u8981\u5360\u636e 472GB \u7684\u5185\u5b58, \u4e0a\u9762\u7684\u4ee3\u7801\u4f1a\u6709\u4e24\u4e2a\u6a21\u578b\u526f\u672c, \u8fd9\u610f\u5473\u7740\u5cf0\u503c\u9700\u8981944GB \u5185\u5b58, \u63a5\u8fd11T ,\u8fd9\u662f\u975e\u5e38\u5938\u5f20\u7684\u4e5f\u662f\u4e0d\u53ef\u63a5\u53d7\u7684."}),"\n",(0,r.jsx)(t.p,{children:"\u9996\u5148\u521d\u59cb\u5316\u4e00\u4e2a 1B size \u7684\u6a21\u578b\u5e76\u5b58\u4e0b\u6765,"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:"import torch\n\ndef count_parameters(model):\n    total_params =  sum(p.numel() for p in model.parameters() if p.requires_grad)\n    return total_params / 1e9 \n\ndef model_memory_size_in_megabytes(model):\n    param_size = 0\n    for param in model.parameters():\n        param_size += param.numel() * param.element_size()  \n\n    bytes_in_gb = 1024 * 1024 * 1024 \n    return param_size / bytes_in_gb\n\nclass BigModel(torch.nn.Module):\n    def __init__(self, size):\n        super().__init__()\n        self.linears = nn.ModuleList([nn.Linear(size, size) for i in range(10)])\n\n    def forward(self, x):\n        return self.linears(x)\n\nsize = 10000\nmodel = BigModel(size)\n\n# \u6253\u5370\u6a21\u578b\u7684\u53c2\u6570\u91cf\nprint(f'The model has {count_parameters(model):,} B trainable parameters')\nprint(f\"The model's memory size is approximately {model_memory_size_in_megabytes(model):.2f} GB.\")\ntorch.save(model.state_dict(), 'checkpoint.pth')\n"})}),"\n",(0,r.jsx)(t.p,{children:"\u7136\u540e \u6309\u7167\u4e0a\u9762\u7684\u65b9\u5f0f\u52a0\u8f7d\u6a21\u578b, \u5e76\u7edf\u8ba1cpu \u5185\u5b58\u5360\u7528, torch \u9ed8\u8ba4\u662fFP32 \u683c\u5f0f, 1B\u6a21\u578b\u5360\u7528\u7ea6 4GB \u5185\u5b58(\u5b9e\u9645\u4e3a3.73GB\u5de6\u53f3), \u4e0b\u9762\u4ee3\u7801\u9a8c\u8bc1\u540e\u57fa\u672c\u7b26\u5408\u9884\u671f"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:"def print_usage():\n    pid = os.getpid()\n    py = psutil.Process(pid)\n    memory_use = py.memory_info()[0] / 2. ** 30  # memory use in GB...I think\n    print(f'memory: {memory_use:.2f} GB')\n    print('CPU percent:', psutil.cpu_percent())\n\nprint('Before Load the state_dict:')\nprint_usage()\n"})}),"\n",(0,r.jsxs)(t.blockquote,{children:["\n",(0,r.jsx)(t.p,{children:"Before Load the state_dict:\nmemory: 0.34 GB\nCPU percent: 8.5"}),"\n"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:"start_time = time.time()\nstate_dict = torch.load('checkpoint.pth')\nprint(f'Loading the state_dict took {time.time() - start_time:.2f} seconds')\nprint('After Load the state_dict:')\nprint_usage()\n"})}),"\n",(0,r.jsxs)(t.blockquote,{children:["\n",(0,r.jsx)(t.p,{children:"Loading the state_dict took 2.09 seconds\nAfter Load the state_dict:\nmemory: 4.06 GB\nCPU percent: 7.0"}),"\n"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:"start_time = time.time()\nmodel = BigModel(size)\nprint(f'Init the model took {time.time() - start_time:.2f} seconds')\nprint('After Init the model:')\nprint_usage()\n"})}),"\n",(0,r.jsxs)(t.blockquote,{children:["\n",(0,r.jsx)(t.p,{children:"Init the model took 7.23 seconds\nAfter Init the model:\nmemory: 7.79 GB\nCPU percent: 7.6"}),"\n"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:"start_time = time.time()\nmodel.load_state_dict(state_dict)\nprint(f'Loading the state_dict to model took {time.time() - start_time:.2f} seconds')\nprint('After Load the state_dict to model:')\nprint_usage()\n"})}),"\n",(0,r.jsxs)(t.blockquote,{children:["\n",(0,r.jsx)(t.p,{children:"Loading the state_dict to model took 2.63 seconds\nAfter Load the state_dict to model:\nmemory: 7.79 GB\nCPU percent: 16.4"}),"\n"]}),"\n",(0,r.jsx)(t.h1,{id:"\u95ee\u9898\u89e3\u51b3",children:"\u95ee\u9898\u89e3\u51b3"}),"\n",(0,r.jsxs)(t.h2,{id:"\u4f7f\u7528torchloadmmaptrue",children:["\u4f7f\u7528",(0,r.jsx)(t.code,{children:"torch.load(mmap=True)"})]}),"\n",(0,r.jsx)(t.p,{children:"torch.load\u4e2d\u7684mmap\u53c2\u6570\u56fe\u89e3\u51b3\u4e0a\u8ff0\u4e24\u4e2a\u95ee\u9898\u3002\u987e\u540d\u601d\u4e49\uff0cmmap\u5173\u952e\u5b57\u53c2\u6570 to torch.load \u4f7f\u7528mmap \u8c03\u7528 \uff0c\u5c06\u78c1\u76d8\u4e0a\u7684\u6587\u4ef6\u6620\u5c04\u5230\u865a\u62df\u5185\u5b58\uff0c\u5e76\u8ba9\u64cd\u4f5c\u7cfb\u7edf\u81ea\u52a8\u5904\u7406\u5230\u7269\u7406\u5185\u5b58\u7684\u52a0\u8f7d\u548c\u5378\u8f7d\u3002\u5f53\u8fd9\u4e2a\u6807\u5fd7\u88ab\u4f20\u9012\u65f6\uff0c\u5f20\u91cf\u5b58\u50a8\u5c06\u88ab\u5185\u5b58\u6620\u5c04\u3002"}),"\n",(0,r.jsxs)(t.blockquote,{children:["\n",(0,r.jsx)(t.p,{children:"loading time with mmap=0.003424406051635742\nmemory: 0.34 GB"}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:"\u901a\u8fc7\u4e0a\u9762\u5bf9\u6bd4,\u6211\u4eec\u53ef\u4ee5\u53d1\u73b0 \u4f7f\u7528mmap\u53ef\u4ee5\u52a0\u901f\u6a21\u578b\u52a0\u8f7d\u5e76\u51cf\u5c11\u5185\u5b58\u5360\u7528, \u5bf9\u4e8e236B\u7684\u6a21\u578b, \u6211\u4eec\u5b9e\u9645\u4e0a\u5e76\u4e0d\u9700\u8981 1TB\u7684 CPU\u5185\u5b58\u6765\u5b8c\u6210\u8f6c\u6362"}),"\n",(0,r.jsxs)(t.h2,{id:"\u4f7f\u7528-torchdevicemeta",children:["\u4f7f\u7528 ",(0,r.jsx)(t.code,{children:"torch.device('meta')"})]}),"\n",(0,r.jsx)(t.p,{children:"\u5f53\u6a21\u578bsize \u5de8\u5927\u65f6, \u6a21\u578b\u521d\u59cb\u5316\u4e5f\u9700\u8981\u5de8\u5927\u65f6\u95f4, \u6211\u4eec\u6269\u5927\u4e00\u4e0b\u6a21\u578bsize\u523025B, \u521d\u59cb\u5316\u4e00\u4e2a\u6a21\u578b\u5c31\u9700\u8981\u63a5\u8fd13\u5206\u949f."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'size = 50000\nstart_time = time.time()\nmodel = BigModel(size)\nend_time = time.time()\nprint(f"init time={end_time - start_time}")\nprint(f\'The model has {count_parameters(model):,} B trainable parameters\')\nprint(f"The model\'s memory size is approximately {model_memory_size_in_megabytes(model):.2f} GB.")\n'})}),"\n",(0,r.jsxs)(t.blockquote,{children:["\n",(0,r.jsx)(t.p,{children:"init time=184.56671452522278\nThe model has 25.0005 B trainable parameters\nThe model's memory size is approximately 93.13 GB."}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:"\u4f46\u5728load \u6a21\u578b\u65f6, \u521d\u59cb\u5316\u8fd9\u4e00\u6b65\u662f\u591a\u4f59\u7684, \u6211\u4eec\u5b9e\u9645\u4e0a\u53ea\u9700\u8981\u77e5\u9053\u6a21\u578b\u7684\u6240\u6709 key \u548c \u5bf9\u5e94\u7684 shape\n\u8fd9\u4e2a\u65f6\u5019, torch.device('meta') \u8fd9\u4e2a \u4e0a\u4e0b\u6587\u5c31\u53ef\u4ee5\u53d1\u6325\u4f5c\u7528\u4e86, torch.device() \u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\u786e\u4fdd\u5de5\u5382\u8c03\u7528\u5c06\u50cf\u5b83\u4eec\u88ab\u4f20\u9012\u4e86\u6307\u5b9a\u7684\"device\"\u4f5c\u4e3a\u53c2\u6570\u4e00\u6837\u6267\u884c\u3002\u5728 torch.device('meta') \u4e0a\u7684\u5f20\u91cf\u4e0d\u643a\u5e26\u6570\u636e\u3002\u7136\u800c\uff0c\u5b83\u4eec\u5177\u6709\u5f20\u91cf\u6240\u5177\u6709\u7684\u6240\u6709\u5176\u4ed6\u5143\u6570\u636e\uff0c\u4f8b\u5982.size()\u3001.stride()\u3001.requires_grad\u7b49\u3002"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'with torch.device(\'meta\'):\n   model = BigModel(size)\nmodel.load_state_dict(state_dict, assign=True)\n\nfor n, p in model.named_parameters():\n    assert p.device.type != "meta", f"{n} has not been loaded!"\n'})})]})}function m(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}}}]);