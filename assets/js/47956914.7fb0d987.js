"use strict";(self.webpackChunkblog_sample=self.webpackChunkblog_sample||[]).push([[3986],{4098:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"ml/distribute","title":"pytorch \u5206\u5e03\u5f0f\u901a\u4fe1\u539f\u8bed","description":"\u4e0b\u9762\u901a\u8fc7torch.distributed\u7684send/recv\u63a5\u53e3\u5b9e\u73b0\u4e00\u4e2a\u7b80\u6613\u7684ping-pong \u7a0b\u5e8f\u3002\u7a0b\u5e8f\u529f\u80fd\u5982\u4e0b\uff1a","source":"@site/docs/ml/distribute.md","sourceDirName":"ml","slug":"/ml/distribute","permalink":"/docs/ml/distribute","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/edit/main/website/docs/ml/distribute.md","tags":[{"inline":true,"label":"machine learning","permalink":"/docs/tags/machine-learning"},{"inline":true,"label":"interview","permalink":"/docs/tags/interview"}],"version":"current","lastUpdatedAt":1740785860000,"frontMatter":{"title":"pytorch \u5206\u5e03\u5f0f\u901a\u4fe1\u539f\u8bed","tags":["machine learning","interview"]},"sidebar":"tutorialSidebar","previous":{"title":"python gdb","permalink":"/docs/ml/debug_python"},"next":{"title":"FlashAttention \u539f\u7406","permalink":"/docs/ml/flash_attention"}}');var t=r(4848),a=r(8453);const i={title:"pytorch \u5206\u5e03\u5f0f\u901a\u4fe1\u539f\u8bed",tags:["machine learning","interview"]},o="P2P communication",d={},c=[{value:"\u521d\u59cb\u5316",id:"\u521d\u59cb\u5316",level:2},{value:"\u901a\u4fe1\u903b\u8f91",id:"\u901a\u4fe1\u903b\u8f91",level:2},{value:"\u4efb\u52a1\u542f\u52a8",id:"\u4efb\u52a1\u542f\u52a8",level:2},{value:"broadcast",id:"broadcast",level:2},{value:"scatter",id:"scatter",level:2},{value:"gather",id:"gather",level:2},{value:"all-gather",id:"all-gather",level:2},{value:"all-reduce",id:"all-reduce",level:2}];function l(n){const e={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"p2p-communication",children:"P2P communication"})}),"\n",(0,t.jsx)(e.p,{children:"\u4e0b\u9762\u901a\u8fc7torch.distributed\u7684send/recv\u63a5\u53e3\u5b9e\u73b0\u4e00\u4e2a\u7b80\u6613\u7684ping-pong \u7a0b\u5e8f\u3002\u7a0b\u5e8f\u529f\u80fd\u5982\u4e0b\uff1a"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"tensor \u521d\u59cb\u503c\u4e3a0"}),"\n",(0,t.jsx)(e.li,{children:"process 0 \uff08\u6216\u53ebrank 0)\uff1a\u5bf9tensor\u52a01\uff0c\u7136\u540e\u53d1\u9001\u7ed9process 1(\u6216\u53ebrank1\uff09\uff1b"}),"\n",(0,t.jsx)(e.li,{children:"process 1\uff1a\u63a5\u6536\u5230tensor\u540e\uff0c\u5bf9tensor \u52a02\uff0c\u7136\u540e\u5728\u53d1\u9001\u7ed9process 0;"}),"\n",(0,t.jsx)(e.li,{children:"process 0\uff1a\u63a5\u6536process1\u53d1\u9001\u7684tensor\uff1b"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"\u521d\u59cb\u5316",children:"\u521d\u59cb\u5316"}),"\n",(0,t.jsxs)(e.p,{children:["pytorch\u7684\u5206\u5e03\u5f0f\u6a21\u5757\u901a\u8fc7",(0,t.jsx)(e.code,{children:"torch.distributed.init_process_group"}),"\u6765\u5b8c\u6210"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"\u901a\u8fc7\u73af\u5883\u53d8\u91cfMASTER_ADDR\u548cMASTER_PORT\u8bbe\u7f6erank0\u7684IP\u548cPORT\u4fe1\u606f\uff0crank0\u7684\u4f5c\u7528\u76f8\u5f53\u4e8e\u662f\u534f\u8c03\u8282\u70b9\uff0c\u9700\u8981\u5176\u4ed6\u6240\u6709\u8282\u70b9\u77e5\u9053\u5176\u8bbf\u95ee\u5730\u5740;"}),"\n",(0,t.jsx)(e.li,{children:"\u672c\u4f8b\u4e2d\u540e\u7aef\u9009\u62e9\u7684\u662fgloo\uff0c\u901a\u8fc7\u8bbe\u7f6eNCCL_DEBUG\u73af\u5883\u53d8\u91cf\u4e3aINFO\uff0c\u8f93\u51faNCCL\u7684\u8c03\u8bd5\u4fe1\u606f\uff1b"}),"\n",(0,t.jsxs)(e.li,{children:["init_process_group\uff1a\u6267\u884c\u7f51\u7edc\u901a\u4fe1\u6a21\u5757\u7684\u521d\u59cb\u5316\u5de5\u4f5c","\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"backend\uff1a\u8bbe\u7f6e\u540e\u7aef\u7f51\u7edc\u901a\u4fe1\u7684\u5b9e\u73b0\u5e93\uff0c\u53ef\u9009\u7684\u4e3agloo\u3001nccl\u548cmpi\uff1b\u672c\u4f8b\u9009\u62e9gloo\u4f5c\u4e3abackend(\u6ce8\uff1anccl\u4e0d\u652f\u6301p2p\u901a\u4fe1\uff0cmpi\u9700\u8981\u91cd\u65b0\u7f16\u8bd1pytorch\u6e90\u7801\u624d\u80fd\u4f7f\u7528\uff09\uff1b"}),"\n",(0,t.jsx)(e.li,{children:"rank\uff1a\u4e3a\u5f53\u524drank\u7684index\uff0c\u7528\u4e8e\u6807\u8bb0\u5f53\u524d\u662f\u7b2c\u51e0\u4e2arank\uff0c\u53d6\u503c\u4e3a0\u5230work_size - 1\u4e4b\u95f4\u7684\u503c\uff1b"}),"\n",(0,t.jsx)(e.li,{children:"world_size: \u6709\u591a\u5c11\u4e2a\u8fdb\u7a0b\u53c2\u4e0e\u5230\u5206\u5e03\u5f0f\u8bad\u7ec3\u4e2d;"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"def init_process(rank_id, size, fn, backend='gloo'):\n    \"\"\" Initialize the distributed environment. \"\"\"\n    os.environ['MASTER_ADDR'] = '127.0.0.1'\n    os.environ['MASTER_PORT'] = '29500'\n    dist.init_process_group(backend, rank=rank_id, world_size=size)\n    fn(rank_id, size)\n"})}),"\n",(0,t.jsx)(e.h2,{id:"\u901a\u4fe1\u903b\u8f91",children:"\u901a\u4fe1\u903b\u8f91"}),"\n",(0,t.jsx)(e.p,{children:"\u4e0b\u9762\u7684\u4ee3\u7801\u5c55\u793a\u4e86rank0\u548crank1\u8fdb\u884cping-pong\u901a\u4fe1\u7684\u5b9e\u73b0\uff1a"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"\u901a\u8fc7rank_id\u6765\u533a\u5206\u5f53\u524d\u5e94\u8be5\u6267\u884c\u54ea\u4e00\u4e2arank\u7684\u4e1a\u52a1\u903b\u8f91\uff1b"}),"\n",(0,t.jsxs)(e.li,{children:["pytorch \u4e2d\u901a\u8fc7",(0,t.jsx)(e.code,{children:"torch.distributed.send(tensor, dst, group=None, tag=0)"})," \u548c",(0,t.jsx)(e.code,{children:"torch.distributed.isend(tensor, dst, group=None, tag=0)"})," \u6765\u5b9e\u73b0tensor\u7684\u53d1\u9001\uff0c\u5176\u4e2dsend\u662f\u540c\u6b65\u51fd\u6570\uff0cisend\u662f\u5f02\u6b65\u51fd\u6570\uff1b","\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"tensor\uff1a\u8981\u53d1\u9001\u7684\u6570\u636e"}),"\n",(0,t.jsx)(e.li,{children:"dst\uff1a\u76ee\u6807rank\uff0c\u586b\u5199\u76ee\u6807rank id\u5373\u53ef"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["pytorch\u4e2d\u901a\u8fc7",(0,t.jsx)(e.code,{children:"torch.distributed.recv(tensor, src=None, group=None, tag=0)"}),"\u548c",(0,t.jsx)(e.code,{children:"torch.distributed.irecv(tensor, src=None, group=None, tag=0)"}),"\u6765\u5b9e\u73b0tensor\u7684\u63a5\u6536\uff0c\u5176\u4e2drecv\u662f\u540c\u6b65\u51fd\u6570\uff0cirecv\u662f\u5f02\u6b65\u51fd\u6570\uff1b","\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"tensor\uff1a\u63a5\u6536\u7684\u6570\u636e"}),"\n",(0,t.jsx)(e.li,{children:"src\uff1a\u63a5\u6536\u6570\u636e\u6765\u6e90\u7684rank id"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"def run(rank_id, size):\n    tensor = torch.zeros(1)\n    if rank_id == 0:\n        tensor += 1\n        # Send the tensor to process 1\n        dist.send(tensor=tensor, dst=1)\n        print('after send, Rank ', rank_id, ' has data ', tensor[0])\n        \n        dist.recv(tensor=tensor, src=1)\n        print('after recv, Rank ', rank_id, ' has data ', tensor[0])\n    else:\n        # Receive tensor from process 0\n        dist.recv(tensor=tensor, src=0)\n        print('after recv, Rank ', rank_id, ' has data ', tensor[0])\n        \n        tensor += 1\n        dist.send(tensor=tensor, dst=0)\n        print('after send, Rank ', rank_id, ' has data ', tensor[0])\n"})}),"\n",(0,t.jsx)(e.h2,{id:"\u4efb\u52a1\u542f\u52a8",children:"\u4efb\u52a1\u542f\u52a8"}),"\n",(0,t.jsx)(e.p,{children:"\u901a\u8fc7\u4e0b\u9762\u7684\u4ee3\u7801\u6765\u542f\u52a8\u4e24\u4e2aprocess\u8fdb\u884cping-pong\u901a\u4fe1\uff1a"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"\u8fd9\u91cc\u4f7f\u7528torch.multiprocessing\u6765\u542f\u52a8\u591a\u8fdb\u7a0b\uff0ctorch.multiprocessing\u662fpython\u5e93\u4e2dmultiprocessing\u7684\u5c01\u88c5\uff0c\u5e76\u4e14\u517c\u5bb9\u4e86\u6240\u6709\u7684\u63a5\u53e3"}),"\n",(0,t.jsx)(e.li,{children:"multiprocessing.set_start_method : \u7528\u4e8e\u6307\u5b9a\u521b\u5efachild process\u7684\u65b9\u5f0f\uff0c\u53ef\u9009\u7684\u503c\u4e3afork\u3001spawn\u548cforkserver\u3002\u4f7f\u7528spawn\uff0cchild process\u4ec5\u4f1a\u7ee7\u627fparent process\u7684\u5fc5\u8981resource\uff0cfile descriptor\u548chandle\u5747\u4e0d\u4f1a\u7ee7\u627f\u3002"}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"multiprocessing.Process(group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None)"})," \uff1a \u7528\u6765\u542f\u52a8child process"]}),"\n"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'if __name__ == "__main__":\n    size = 2\n    processes = []\n    mp.set_start_method("spawn")\n    for rank in range(size):\n        p = mp.Process(target=init_process, args=(rank, size, run))\n        p.start()\n        processes.append(p)\n\n    for p in processes:\n        p.join()\n'})}),"\n",(0,t.jsx)(e.h1,{id:"collective-communication",children:"collective communication"}),"\n",(0,t.jsx)(e.h2,{id:"broadcast",children:"broadcast"}),"\n",(0,t.jsxs)(e.p,{children:["\u5728pytorch\u4e2d\u901a\u8fc7",(0,t.jsx)(e.code,{children:"torch.distributed.broadcast(tensor, src, group=None, async_op=False)"})," \u6765broadcast\u901a\u4fe1\u3002"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"\u53c2\u6570tensor\u5728src rank\u662finput tensor\uff0c\u5728\u5176\u4ed6rank\u662foutput tensor\uff1b"}),"\n",(0,t.jsx)(e.li,{children:"\u53c2\u6570src\u8bbe\u7f6e\u54ea\u4e2arank\u8fdb\u884cbroadcast\uff0c\u9ed8\u8ba4\u4e3arank 0\uff1b"}),"\n"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import os\nimport torch\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\n\ndef run(rank_id, size):\n    tensor = torch.arange(2, dtype=torch.int64) + 1 + 2 * rank_id\n    print('before broadcast',' Rank ', rank_id, ' has data ', tensor)\n    dist.broadcast(tensor, src = 0)\n    print('after broadcast',' Rank ', rank_id, ' has data ', tensor)\n\n\n\n\ndef init_process(rank_id, size, fn, backend='gloo'):\n    \"\"\" Initialize the distributed environment. \"\"\"\n    os.environ['MASTER_ADDR'] = '127.0.0.1'\n    os.environ['MASTER_PORT'] = '29500'\n    dist.init_process_group(backend, rank=rank_id, world_size=size)\n    fn(rank_id, size)\n\n\nif __name__ == \"__main__\":\n    size = 4\n    processes = []\n    mp.set_start_method(\"spawn\")\n    for rank in range(size):\n        p = mp.Process(target=init_process, args=(rank, size, run))\n        p.start()\n        processes.append(p)\n\n    for p in processes:\n        p.join()\n"})}),"\n",(0,t.jsx)(e.p,{children:"\u8f93\u51fa:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"\u4e00\u5171\u67094\u4e2arank\u53c2\u4e0e\u4e86broadcast\u8ba1\u7b97\uff0c\u8ba1\u7b97\u4e4b\u524d\uff1arank0 \u4e3a[1, 2]\uff0crank1 \u4e3a[3, 4]\uff0c rank2\u4e3a[5, 6]\uff0c rank3\u4e3a[7, 8]"}),"\n",(0,t.jsx)(e.li,{children:"broadcast\u8ba1\u7b97\u4e4b\u540e\uff0c\u6240\u6709rank\u7684\u7ed3\u679c\u5747rank0\u7684tensor\u5373[1, 2]\uff08\u56e0\u4e3a\u5728\u8c03\u7528torch.distributed.broadcast\u65f6src\u8bbe\u7f6e\u4e3a0\uff0c\u8868\u793arank0\u8fdb\u884cbroadcast\uff09"}),"\n"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-shell",children:"before broadcast  Rank  1  has data  tensor([3, 4])\nbefore broadcast  Rank  0  has data  tensor([1, 2])\nbefore broadcast  Rank  2  has data  tensor([5, 6])\nbefore broadcast  Rank  3  has data  tensor([7, 8])\nafter broadcast  Rank  1  has data  tensor([1, 2])\nafter broadcast  Rank  0  has data  tensor([1, 2])\nafter broadcast  Rank  2  has data  tensor([1, 2])\nafter broadcast  Rank  3  has data  tensor([1, 2])\n"})}),"\n",(0,t.jsx)(e.h2,{id:"scatter",children:"scatter"}),"\n",(0,t.jsxs)(e.p,{children:["\u5728pytorch\u4e2d\u901a\u8fc7",(0,t.jsx)(e.code,{children:"torch.distributed.scatter(tensor, scatter_list=None, src=0, group=None, async_op=False)"})," \u6765\u5b9e\u73b0scatter\u901a\u4fe1\u3002"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"\u53c2\u6570tensor\u4e3a\u9664 src rank\u5916\uff0c\u5176\u4ed6rank\u83b7\u53d6output tensor\u7684\u53c2\u6570"}),"\n",(0,t.jsx)(e.li,{children:"scatter_list\u4e3a\u8fdb\u884cscatter\u8ba1\u7b97tensor list"}),"\n",(0,t.jsx)(e.li,{children:"\u53c2\u6570src\u8bbe\u7f6e\u54ea\u4e2arank\u8fdb\u884cscatter\uff0c\u9ed8\u8ba4\u4e3arank 0\uff1b"}),"\n"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import os\nimport torch\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\n\ndef run(rank_id, size):\n    tensor = torch.arange(2, dtype=torch.int64) + 1 + 2 * rank_id\n    print('before scatter',' Rank ', rank_id, ' has data ', tensor)\n    if rank_id == 0:\n        scatter_list = [torch.tensor([0,0]), torch.tensor([1,1]), torch.tensor([2,2]), torch.tensor([3,3])]\n        print('scater list:', scatter_list)\n        dist.scatter(tensor, src = 0, scatter_list=scatter_list)\n    else:\n        dist.scatter(tensor, src = 0)\n    print('after scatter',' Rank ', rank_id, ' has data ', tensor)\n\n\n\n\ndef init_process(rank_id, size, fn, backend='gloo'):\n    \"\"\" Initialize the distributed environment. \"\"\"\n    os.environ['MASTER_ADDR'] = '127.0.0.1'\n    os.environ['MASTER_PORT'] = '29500'\n    dist.init_process_group(backend, rank=rank_id, world_size=size)\n    fn(rank_id, size)\n\n\nif __name__ == \"__main__\":\n    size = 4\n    processes = []\n    mp.set_start_method(\"spawn\")\n    for rank in range(size):\n        p = mp.Process(target=init_process, args=(rank, size, run))\n        p.start()\n        processes.append(p)\n\n    for p in processes:\n        p.join()\n"})}),"\n",(0,t.jsx)(e.p,{children:"\u8f93\u51fa\uff1a"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["\u4e00\u5171\u67094\u4e2arank\u53c2\u4e0e\u4e86scatter\u8ba1\u7b97\uff0c\u8ba1\u7b97\u4e4b\u524d\uff1arank0 \u4e3a[1, 2]\uff0crank1 \u4e3a[3, 4]\uff0c rank2\u4e3a[5, 6]\uff0c rank3\u4e3a[7, 8]\uff0cscatter list\u4e3a",(0,t.jsx)(e.code,{children:"[0,0], [1,1], [2,2], [3,3]"}),";"]}),"\n",(0,t.jsxs)(e.li,{children:["scatter\u8ba1\u7b97\u4e4b\u540e\uff0crank\u6309\u987a\u5e8f\u88ab\u5206\u914dscatter list\u7684\u6bcf\u4e00\u4e2atensor, rank0\u4e3a",(0,t.jsx)(e.code,{children:"[0,0]"}),", rank1\u4e3a [1, 1] , rank2\u4e3a [2, 2], rank3[3, 3];"]}),"\n"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-shell",children:"before scatter  Rank  1  has data  tensor([3, 4])\nbefore scatter  Rank  0  has data  tensor([1, 2])\nbefore scatter  Rank  2  has data  tensor([5, 6])\nscater list: [tensor([0, 0]), tensor([1, 1]), tensor([2, 2]), tensor([3, 3])]\nbefore scatter  Rank  3  has data  tensor([7, 8])\nafter scatter  Rank  1  has data  tensor([1, 1])\nafter scatter  Rank  0  has data  tensor([0, 0])\nafter scatter  Rank  3  has data  tensor([3, 3])\nafter scatter  Rank  2  has data  tensor([2, 2])\n"})}),"\n",(0,t.jsx)(e.h2,{id:"gather",children:"gather"}),"\n",(0,t.jsxs)(e.p,{children:["\u5728pytorch\u4e2d\u901a\u8fc7",(0,t.jsx)(e.code,{children:"torch.distributed.gather(tensor, gather_list=None, dst=0, group=None, async_op=False)"})," \u6765\u5b9e\u73b0gather\u7684\u901a\u4fe1\uff1b"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"\u53c2\u6570tensor\u662f\u6240\u6709rank\u7684input tensor"}),"\n",(0,t.jsx)(e.li,{children:"gather_list\u662fdst rank\u7684output \u7ed3\u679c"}),"\n",(0,t.jsx)(e.li,{children:"dst\u4e3a\u76ee\u6807dst"}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"\u8fd9\u91cc\u9700\u8981\u6ce8\u610f\u7684\u662f\u5728rank 0\uff08\u4e5f\u5c31\u662fdst rank\uff09\u4e2d\u8981\u6307\u5b9agather_list\uff0c\u5e76\u4e14\u8981\u5728gather_list\u6784\u5efa\u597d\u7684tensor\uff0c\u5426\u662f\u4f1a\u62a5\u9519"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import os\nimport torch\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\n\ndef run(rank_id, size):\n    tensor = torch.arange(2, dtype=torch.int64) + 1 + 2 * rank_id\n    print('before gather',' Rank ', rank_id, ' has data ', tensor)\n    if rank_id == 0:\n        gather_list = [torch.zeros(2, dtype=torch.int64) for _ in range(4)]\n        dist.gather(tensor, dst = 0, gather_list=gather_list)\n        print('after gather',' Rank ', rank_id, ' has data ', tensor)\n        print('gather_list:', gather_list)\n    else:\n        dist.gather(tensor, dst = 0)\n        print('after gather',' Rank ', rank_id, ' has data ', tensor)\n\ndef init_process(rank_id, size, fn, backend='gloo'):\n    \"\"\" Initialize the distributed environment. \"\"\"\n    os.environ['MASTER_ADDR'] = '127.0.0.1'\n    os.environ['MASTER_PORT'] = '29500'\n    dist.init_process_group(backend, rank=rank_id, world_size=size)\n    fn(rank_id, size)\n\n\nif __name__ == \"__main__\":\n    size = 4\n    processes = []\n    mp.set_start_method(\"spawn\")\n    for rank in range(size):\n        p = mp.Process(target=init_process, args=(rank, size, run))\n        p.start()\n        processes.append(p)\n\n    for p in processes:\n        p.join()\n"})}),"\n",(0,t.jsx)(e.p,{children:"\u8f93\u51fa\uff1a"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"\u4e00\u5171\u67094\u4e2arank\u53c2\u4e0e\u4e86gather\u8ba1\u7b97\uff0c\u8ba1\u7b97\u4e4b\u524d\uff1arank0 \u4e3a[1, 2]\uff0crank1 \u4e3a[3, 4]\uff0c rank2\u4e3a[5, 6]\uff0c rank3\u4e3a[7, 8]"}),"\n",(0,t.jsx)(e.li,{children:"gather\u8ba1\u7b97\u4e4b\u540e\uff0cgather_list\u7684\u503c\u4e3a[tensor([1, 2]), tensor([3, 4]), tensor([5, 6]), tensor([7, 8])]"}),"\n"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-shell",children:"before gather  Rank  0  has data  tensor([1, 2])\nbefore gather  Rank  3  has data  tensor([7, 8])\nafter gather  Rank  3  has data  tensor([7, 8])\nbefore gather  Rank  1  has data  tensor([3, 4])\nbefore gather  Rank  2  has data  tensor([5, 6])\nafter gather  Rank  1  has data  tensor([3, 4])\nafter gather  Rank  2  has data  tensor([5, 6])\nafter gather  Rank  0  has data  tensor([1, 2])\ngather_list: [tensor([1, 2]), tensor([3, 4]), tensor([5, 6]), tensor([7, 8])]\n"})}),"\n",(0,t.jsx)(e.h1,{id:"reduce",children:"reduce"}),"\n",(0,t.jsxs)(e.p,{children:["\u5728pytorch\u4e2d\u901a\u8fc7",(0,t.jsx)(e.code,{children:"torch.distributed.reduce(tensor, dst, op=<ReduceOp.SUM: 0>, group=None, async_op=False)"}),"\u6765\u5b9e\u73b0reduce\u901a\u4fe1\uff1b"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"\u53c2\u6570tensor\u662f\u9700\u8981\u8fdb\u884creduce\u8ba1\u7b97\u7684\u6570\u636e\uff0c\u5bf9\u4e8edst rank\u6765\u8bf4\uff0ctensor\u4e3a\u6700\u7ec8reduce\u7684\u7ed3\u679c"}),"\n",(0,t.jsx)(e.li,{children:"\u53c2\u6570dist\u8bbe\u7f6e\u76ee\u6807rank\u7684ID"}),"\n",(0,t.jsx)(e.li,{children:"\u53c2\u6570op\u4e3areduce\u7684\u8ba1\u7b97\u65b9\u5f0f\uff0cpytorch\u4e2d\u652f\u6301\u7684\u8ba1\u7b97\u65b9\u5f0f\u6709SUM, PRODUCT, MIN, MAX, BAND, BOR, and BXOR"}),"\n"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import os\nimport torch\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\n\ndef run(rank_id, size):\n    tensor = torch.arange(2, dtype=torch.int64) + 1 + 2 * rank_id\n    print('before reudce',' Rank ', rank_id, ' has data ', tensor)\n    dist.reduce(tensor, dst = 3, op=dist.ReduceOp.SUM,)\n    print('after reudce',' Rank ', rank_id, ' has data ', tensor)\n\n\ndef init_process(rank_id, size, fn, backend='gloo'):\n    \"\"\" Initialize the distributed environment. \"\"\"\n    os.environ['MASTER_ADDR'] = '127.0.0.1'\n    os.environ['MASTER_PORT'] = '29500'\n    dist.init_process_group(backend, rank=rank_id, world_size=size)\n    fn(rank_id, size)\n\n\nif __name__ == \"__main__\":\n    size = 4\n    processes = []\n    mp.set_start_method(\"spawn\")\n    for rank in range(size):\n        p = mp.Process(target=init_process, args=(rank, size, run))\n        p.start()\n        processes.append(p)\n\n    for p in processes:\n        p.join()\n"})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"\u4e00\u5171\u67094\u4e2arank\u53c2\u4e0e\u4e86gather\u8ba1\u7b97\uff0c\u8ba1\u7b97\u4e4b\u524d\uff1arank0 \u4e3a[1, 2]\uff0crank1 \u4e3a[3, 4]\uff0c rank2\u4e3a[5, 6]\uff0c rank3\u4e3a[7, 8]\uff1bdst rank\u8bbe\u7f6e\u4e3a3"}),"\n",(0,t.jsx)(e.li,{children:"\u53ef\u89c1rank 3\u4e3areduce sum\u8ba1\u7b97\u7684\u6700\u7ec8\u7ed3\u679c\uff1b"}),"\n",(0,t.jsx)(e.li,{children:"\u9700\u8981\u6ce8\u610f\u8fd9\u91cc\u6709\u4e2a\u526f\u4f5c\u7528\uff0c\u5c31\u662frank 0\u3001rank 1\u548crank 2\u7684tensor\u4e5f\u4f1a\u88ab\u4fee\u6539"}),"\n"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-shell",children:"before reudce  Rank  3  has data  tensor([7, 8])\nbefore reudce  Rank  0  has data  tensor([1, 2])\nbefore reudce  Rank  2  has data  tensor([5, 6])\nbefore reudce  Rank  1  has data  tensor([3, 4])\nafter reudce  Rank  1  has data  tensor([15, 18])\nafter reudce  Rank  0  has data  tensor([16, 20])\nafter reudce  Rank  3  has data  tensor([16, 20]) # reduce \u7684\u6700\u7ec8\u7ed3\u679c\nafter reudce  Rank  2  has data  tensor([12, 14])\n"})}),"\n",(0,t.jsx)(e.h2,{id:"all-gather",children:"all-gather"}),"\n",(0,t.jsxs)(e.p,{children:["\u5728pytorch\u4e2d\u901a\u8fc7",(0,t.jsx)(e.code,{children:"torch.distributed.all_gather(tensor_list, tensor, group=None, async_op=False)"}),"\u6765\u5b9e\u73b0\u3002"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"\u53c2\u6570tensor_list\uff0crank\u4ece\u8be5\u53c2\u6570\u4e2d\u83b7\u53d6all-gather\u7684\u7ed3\u679c"}),"\n",(0,t.jsx)(e.li,{children:"\u53c2\u6570tensor\uff0c\u6bcf\u4e2arank\u53c2\u4e0eall-gather\u8ba1\u7b97\u8f93\u5165\u6570\u636e"}),"\n"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import os\nimport torch\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\n\ndef run(rank_id, size):\n    tensor = torch.arange(2, dtype=torch.int64) + 1 + 2 * rank_id\n    print('before gather',' Rank ', rank_id, ' has data ', tensor)\n    gather_list = [torch.zeros(2, dtype=torch.int64) for _ in range(4)]\n    dist.all_gather(gather_list, tensor)\n    print('after gather',' Rank ', rank_id, ' has data ', tensor)\n    print('after gather',' Rank ', rank_id, ' has gather list ', gather_list)\n\n\ndef init_process(rank_id, size, fn, backend='gloo'):\n    \"\"\" Initialize the distributed environment. \"\"\"\n    os.environ['MASTER_ADDR'] = '127.0.0.1'\n    os.environ['MASTER_PORT'] = '29500'\n    dist.init_process_group(backend, rank=rank_id, world_size=size)\n    fn(rank_id, size)\n\n\nif __name__ == \"__main__\":\n    size = 4\n    processes = []\n    mp.set_start_method(\"spawn\")\n    for rank in range(size):\n        p = mp.Process(target=init_process, args=(rank, size, run))\n        p.start()\n        processes.append(p)\n\n    for p in processes:\n        p.join()\n"})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"\u4e00\u5171\u67094\u4e2arank\u53c2\u4e0e\u4e86gather\u8ba1\u7b97\uff0c\u8ba1\u7b97\u4e4b\u524d\uff1arank0 \u4e3a[1, 2]\uff0crank1 \u4e3a[3, 4]\uff0c rank2\u4e3a[5, 6]\uff0c rank3\u4e3a[7, 8]\uff1b"}),"\n",(0,t.jsx)(e.li,{children:"\u6267\u884c\u5b8cgather_list\u540e\uff0c\u6bcf\u4e2arank\u5747\u53ef\u4ee5\u62ff\u5230\u6700\u7ec8gather_list\u7684\u7ed3\u679c"}),"\n"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-shell",children:"before gather  Rank  0  has data  tensor([1, 2])\nbefore gather  Rank  2  has data  tensor([5, 6])\nbefore gather  Rank  3  has data  tensor([7, 8])\nbefore gather  Rank  1  has data  tensor([3, 4])\nafter gather  Rank  1  has data  tensor([3, 4])\nafter gather  Rank  0  has data  tensor([1, 2])\nafter gather  Rank  3  has data  tensor([7, 8])\nafter gather  Rank  2  has data  tensor([5, 6])\nafter gather  Rank  1  has gather list  [tensor([1, 2]), tensor([3, 4]), tensor([5, 6]), tensor([7, 8])]\nafter gather  Rank  0  has gather list  [tensor([1, 2]), tensor([3, 4]), tensor([5, 6]), tensor([7, 8])]\nafter gather  Rank  3  has gather list  [tensor([1, 2]), tensor([3, 4]), tensor([5, 6]), tensor([7, 8])]\nafter gather  Rank  2  has gather list  [tensor([1, 2]), tensor([3, 4]), tensor([5, 6]), tensor([7, 8])]\n"})}),"\n",(0,t.jsx)(e.h2,{id:"all-reduce",children:"all-reduce"}),"\n",(0,t.jsxs)(e.p,{children:["\u5728pytorch\u4e2d\u901a\u8fc7",(0,t.jsx)(e.code,{children:"torch.distributed.all_reduce(tensor, op=<ReduceOp.SUM: 0>, group=None, async_op=False)"})," \u6765\u5b9e\u73b0all-reduce\u7684\u8c03\u7528\uff1b"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import os\nimport torch\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\n\ndef run(rank_id, size):\n    tensor = torch.arange(2, dtype=torch.int64) + 1 + 2 * rank_id\n    print('before reudce',' Rank ', rank_id, ' has data ', tensor)\n    dist.all_reduce(tensor, op=dist.ReduceOp.SUM)\n    print('after reudce',' Rank ', rank_id, ' has data ', tensor)\n\n\ndef init_process(rank_id, size, fn, backend='gloo'):\n    \"\"\" Initialize the distributed environment. \"\"\"\n    os.environ['MASTER_ADDR'] = '127.0.0.1'\n    os.environ['MASTER_PORT'] = '29500'\n    dist.init_process_group(backend, rank=rank_id, world_size=size)\n    fn(rank_id, size)\n\n\nif __name__ == \"__main__\":\n    size = 4\n    processes = []\n    mp.set_start_method(\"spawn\")\n    for rank in range(size):\n        p = mp.Process(target=init_process, args=(rank, size, run))\n        p.start()\n        processes.append(p)\n\n    for p in processes:\n        p.join()\n"})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"\u4e00\u5171\u67094\u4e2arank\u53c2\u4e0e\u4e86all-reduce\u8ba1\u7b97\uff0c\u8ba1\u7b97\u4e4b\u524d\uff1arank0 \u4e3a[1, 2]\uff0crank1 \u4e3a[3, 4]\uff0c rank2\u4e3a[5, 6]\uff0c rank3\u4e3a[7, 8]"}),"\n",(0,t.jsx)(e.li,{children:"all-reduce\u8ba1\u7b97\u4e4b\u540e\uff0c\u6240\u6709rank\u7684\u7ed3\u679c\u5747\u76f8\u540c\uff0c\u4e3arank0-rank3\u7684tensor\u8ba1\u7b97sum\u7684\u7ed3\u679c[1+3 + 5 + 7, 2 + 4 + 6 + 8]=[16, 20]"}),"\n"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"before reudce  Rank  3  has data  tensor([7, 8])\nbefore reudce  Rank  2  has data  tensor([5, 6])\nbefore reudce  Rank  0  has data  tensor([1, 2])\nbefore reudce  Rank  1  has data  tensor([3, 4])\nafter reudce  Rank  0  has data  tensor([16, 20])\nafter reudce  Rank  3  has data  tensor([16, 20])\nafter reudce  Rank  2  has data  tensor([16, 20])\nafter reudce  Rank  1  has data  tensor([16, 20])\n"})})]})}function h(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(l,{...n})}):l(n)}},8453:(n,e,r)=>{r.d(e,{R:()=>i,x:()=>o});var s=r(6540);const t={},a=s.createContext(t);function i(n){const e=s.useContext(a);return s.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:i(n.components),s.createElement(a.Provider,{value:e},n.children)}}}]);