"use strict";(self.webpackChunkblog_sample=self.webpackChunkblog_sample||[]).push([[7545],{9190:(n,t,e)=>{e.r(t),e.d(t,{assets:()=>_,contentTitle:()=>s,default:()=>d,frontMatter:()=>i,metadata:()=>a,toc:()=>c});var o=e(5893),r=e(1151);const i={title:"OpenAITriton MLIR \u7b2c\u4e00\u7ae0 Triton DSL",tags:["work"],editor:"caroot"},s=void 0,a={id:"ml/openai_triton/MLIR",title:"OpenAITriton MLIR \u7b2c\u4e00\u7ae0 Triton DSL",description:"Triton DSL\u505a\u77e9\u9635\u4e58\u6cd5",source:"@site/docs/ml/openai_triton/MLIR.md",sourceDirName:"ml/openai_triton",slug:"/ml/openai_triton/MLIR",permalink:"/docs/ml/openai_triton/MLIR",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/edit/main/website/docs/ml/openai_triton/MLIR.md",tags:[{label:"work",permalink:"/docs/tags/work"}],version:"current",lastUpdatedAt:1719151396,formattedLastUpdatedAt:"Jun 23, 2024",frontMatter:{title:"OpenAITriton MLIR \u7b2c\u4e00\u7ae0 Triton DSL",tags:["work"],editor:"caroot"},sidebar:"tutorialSidebar",previous:{title:"openai_triton",permalink:"/docs/ml/openai_triton/"},next:{title:"optimization",permalink:"/docs/ml/optimization/"}},_={},c=[{value:"Triton DSL\u505a\u77e9\u9635\u4e58\u6cd5",id:"triton-dsl\u505a\u77e9\u9635\u4e58\u6cd5",level:2},{value:"\u5b9a\u4e49kernel",id:"\u5b9a\u4e49kernel",level:3},{value:"Kernel\u7684\u7f16\u5199",id:"kernel\u7684\u7f16\u5199",level:3},{value:"Triton\u7684\u81ea\u52a8\u8c03\u4f18",id:"triton\u7684\u81ea\u52a8\u8c03\u4f18",level:2}];function l(n){const t={code:"code",h2:"h2",h3:"h3",img:"img",p:"p",pre:"pre",...(0,r.a)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.h2,{id:"triton-dsl\u505a\u77e9\u9635\u4e58\u6cd5",children:"Triton DSL\u505a\u77e9\u9635\u4e58\u6cd5"}),"\n",(0,o.jsx)(t.h3,{id:"\u5b9a\u4e49kernel",children:"\u5b9a\u4e49kernel"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'def matmul(a, b):\n    # Check constraints.\n    assert a.shape[1] == b.shape[0], "Incompatible dimensions"\n    assert a.is_contiguous(), "Matrix A must be contiguous"\n    assert b.is_contiguous(), "Matrix B must be contiguous"\n    M, K = a.shape\n    K, N = b.shape\n    # Allocates output.\n    c = torch.empty((M, N), device=a.device, dtype=a.dtype)\n    # 1D launch kernel where each block gets its own program.\n    grid = lambda META: (\n        triton.cdiv(M, META[\'BLOCK_SIZE_M\']) * triton.cdiv(N, META[\'BLOCK_SIZE_N\']),\n    )\n    matmul_kernel[grid](\n        a, b, c,\n        M, N, K,\n        a.stride(0), a.stride(1),\n        b.stride(0), b.stride(1),\n        c.stride(0), c.stride(1),\n        ACTIVATION=activation\n    )\n    return c\n'})}),"\n",(0,o.jsx)(t.h3,{id:"kernel\u7684\u7f16\u5199",children:"Kernel\u7684\u7f16\u5199"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'@triton.jit\ndef matmul_kernel(\n    # Pointers to matrices\n    a_ptr, b_ptr, c_ptr,\n    # Matrix dimensions\n    M, N, K,\n    # The stride variables represent how much to increase the ptr by when moving by 1\n    # element in a particular dimension. E.g. `stride_am` is how much to increase `a_ptr`\n    # by to get the element one row down (A has M rows).\n    stride_am, stride_ak,\n    stride_bk, stride_bn,\n    stride_cm, stride_cn,\n    # Meta-parameters\n    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n    GROUP_SIZE_M: tl.constexpr,\n    ACTIVATION: tl.constexpr,\n):\n    """Kernel for computing the matmul C = A x B.\n    A has shape (M, K), B has shape (K, N) and C has shape (M, N)\n    """\n    # -----------------------------------------------------------\n    # Map program ids `pid` to the block of C it should compute.\n    # This is done in a grouped ordering to promote L2 data reuse.\n    # See above `L2 Cache Optimizations` section for details.\n    pid = tl.program_id(axis=0)\n    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n    group_id = pid // num_pid_in_group\n    first_pid_m = group_id * GROUP_SIZE_M\n    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n    pid_m = first_pid_m + (pid % group_size_m)\n    pid_n = (pid % num_pid_in_group) // group_size_m\n\n    # ----------------------------------------------------------\n    # Create pointers for the first blocks of A and B.\n    # We will advance this pointer as we move in the K direction\n    # and accumulate\n    # `a_ptrs` is a block of [BLOCK_SIZE_M, BLOCK_SIZE_K] pointers\n    # `b_ptrs` is a block of [BLOCK_SIZE_K, BLOCK_SIZE_N] pointers\n    # See above `Pointer Arithmetics` section for details\n    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n    offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N\n    offs_k = tl.arange(0, BLOCK_SIZE_K)\n    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n\n    # -----------------------------------------------------------\n    # Iterate to compute a block of the C matrix.\n    # We accumulate into a `[BLOCK_SIZE_M, BLOCK_SIZE_N]` block\n    # of fp32 values for higher accuracy.\n    # `accumulator` will be converted back to fp16 after the loop.\n    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n        # Load the next block of A and B, generate a mask by checking the K dimension.\n        # If it is out of bounds, set it to 0.\n        a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)\n        b = tl.load(b_ptrs, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K, other=0.0)\n        # We accumulate along the K dimension.\n        accumulator += tl.dot(a, b)\n        # Advance the ptrs to the next K block.\n        a_ptrs += BLOCK_SIZE_K * stride_ak\n        b_ptrs += BLOCK_SIZE_K * stride_bk\n    # You can fuse arbitrary activation functions here\n    # while the accumulator is still in FP32!\n    c = accumulator.to(tl.float16)\n\n    # -----------------------------------------------------------\n    # Write back the block of the output matrix C with masks.\n    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n    tl.store(c_ptrs, c, mask=c_mask)\n'})}),"\n",(0,o.jsx)(t.p,{children:"\u7b2c\u4e00\u4e2a\u90e8\u5206\uff0c\u5148\u6765\u770b\u770bmatmul_kernel\u7684\u8f93\u5165\u53c2\u6570\u6709\u54ea\u4e9b\uff1f\u9996\u5148\u5728Triton\u4e2d\u5b9a\u4e49\u4e00\u4e2akernel\u7684\u65f6\u5019\uff0c\u9700\u8981\u4f7f\u7528@triton.jit\u5bf9\u5176\u8fdb\u884c\u88c5\u9970\u3002a_ptr, b_ptr, c_ptr\u6307\u7684\u662f\u8f93\u5165tensor\u548c\u8f93\u51fatensor\u6240\u5bf9\u5e94\u7684\u9996\u5730\u5740\uff0cM,N,K\u5219\u8868\u793a\u9700\u8981\u8ba1\u7b97\u7684tensor\u7684\u7ef4\u5ea6\u5206\u522b\u4e3a[M, K] x [K, N]\u3002stride_am, stride_ak, stride_bk, stride_bn, stride_cm, stride_cn\u5219\u8868\u793a\u7684\u662f\u5206\u522b\u9488\u5bf9a,b,c\u8fd9\u4e09\u4e2atensor\u6765\u8bf4\uff0c\u8bbf\u95ee\u4e00\u4e2a\u5143\u7d20\u6240\u9700\u8981\u79fb\u52a8\u7684\u6b65\u957f\u3002\u800c\u540e\u9762\u7684BLOCK_SIZE_M, BLOCK_SIZE_N\u7b49\u88ab\u5b9a\u4e49\u4e3atl.constexpr\u7684\u53d8\u91cf\u90fd\u5c5e\u4e8e\u662f\u81ea\u52a8\u8c03\u4f18\u7cfb\u7edf\u4e2d\u53ef\u4ee5\u88ab\u679a\u4e3e\u7684knob\uff0c\u5982\u679c\u4f60\u7528\u8fc7autotvm\u7684\u8bdd\uff0c\u5e94\u8be5\u4e0d\u4f1a\u5f88\u964c\u751f\u3002"}),"\n",(0,o.jsx)(t.p,{children:'\u7b2c\u4e8c\u90e8\u5206\uff0c\u5219\u662f\u5c06id\u5bf9\u5e94\u5230\u8f93\u51fatensor\u7684\u6bcf\u4e2ablock\u4e0a\uff0c\u8fd9\u5757\u7684\u5185\u5bb9\u5728tutorial\u4e2d\u8bb2\u5230\u662f\u4e3a\u4e86\u63d0\u9ad8L2 Cache\u7684\u547d\u4e2d\u7387\u3002\u5728\u6587\u4e2d\uff0copenai\u4f7f\u7528\u4e86\u4e00\u4e2a\u53eb\u505a"super-grouping"\u7684\u540d\u5b57\u6765\u8868\u793a\u4e00\u4e2ablock\u4e2d\u6240\u542b\u6709\u7684block\u7684\u4e2a\u6570\u3002\u5176\u5b9esuper-grouping\u7684\u539f\u7406\u5f88\u7b80\u5355\uff0c\u770b\u4e0b\u56fe\u6240\u793a'}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"Alt text",src:e(4234).Z+"",width:"692",height:"493"})}),"\n",(0,o.jsx)(t.p,{children:"\u5f53\u6211\u4eec\u5728\u8fdb\u884cAxB=C\u7684\u65f6\u5019\uff0c\u5982\u679c\u5728load A\u7684\u6570\u636e\u7684\u65f6\u5019\uff0c\u4ee5\u884c\u4f18\u5148\u7684\u65b9\u5f0f\uff0c\u4e00\u6b21\u6027\u8bfb\u53d69\u4e2ablock\uff0c\u90a3\u4e48\u5982\u679c\u8981\u5f97\u5230C\u77e9\u9635\u7684\u7b2c\u4e00\u884c\u7ed3\u679c\uff0c\u5e76\u4e14C\u7684\u5b58\u50a8\u65b9\u5f0f\u4e5f\u662f\u4ee5\u884c\u4f18\u5148\u7684\u65b9\u5f0f\u8fdb\u884c\uff0c\u603b\u5171\u9700\u8981\u8fdb\u884c9+81=90\u6b21\u5bf9block\u7684load\u7684\u64cd\u4f5c\uff0c9\u6b21\u5bf9block\u7684write\u7684\u64cd\u4f5c\u624d\u80fd\u5f97\u5230\u6240\u8981\u7684\u7ed3\u679c\u3002\u4f46\u662f\uff0c\u5982\u679c\u6211\u4eec\u91c7\u7528\u4e86\u201csuper-grouping\u201d\u7684\u65b9\u5f0f\uff0c\u4e5f\u5c31\u662f\u8bf4\u540c\u6837\u4e3a\u4e86\u5f97\u5230\u5f97\u5230C\u77e9\u9635\u4e2d\u76849\u6b21block\u7684write\u64cd\u4f5c\uff0c\u90a3\u4e48\u5bf9\u4e8eA\u77e9\u9635\u6765\u8bf4\uff0c\u8fdb\u884c9*3\u6b21load\u64cd\u4f5c\uff0cB\u77e9\u9635\u4e5f\u540c\u6837\u8fdb\u884c9*3\u6b21\u7684load\u64cd\u4f5c\uff0c\u5bf9block\u603b\u7684load\u64cd\u4f5c\u5219\u4e3a27+27=54\u6b21\u3002\u524d\u540e\u5bf9\u6bd4\u4e0b\uff0c\u7b2c\u4e00\u79cd\u65b9\u5f0f\u5219\u603b\u5171\u8fdb\u884c\u4e8690\u6b21load+9\u6b21write\uff0c\u800c\u7b2c\u4e8c\u79cd\u91c7\u7528\u4e86super-grouping\u6280\u672f\u5219\u8fdb\u884c\u4e8654\u6b21load\u548c9\u6b21write\u3002\u5e76\u4e14openai\u8fd8\u5728\u5907\u6ce8\u4e2d\u8bf4\u660e\u4e86\u53ef\u4ee5\u5728A100\u4e0a\u7531220TFLOPS\u63d0\u5347\u5230245TFLOPS\u3002\u7b49\u540e\u9762\u53ef\u4ee5\u5bf9\u8be5\u6280\u672f\u4e13\u95e8\u5199\u4e00\u4e2a\u7ae0\u8282\u8fdb\u884c\u4ecb\u7ecd\u548c\u6d4b\u8bd5\u3002"}),"\n",(0,o.jsx)(t.p,{children:"\u7b2c\u4e09\u90e8\u5206\uff0c\u5219\u6bd4\u8f83\u5e38\u89c4\uff0c\u5bf9\u5e94\u5230CUDA\u7f16\u7a0b\u4e2d\uff0c\u5176\u5b9e\u5c31\u662f\u5728\u63a2\u7d22\u5982\u4f55\u901a\u8fc7Triton DSL\u53bb\u8bbf\u95ee\u6bcf\u4e2ablock\uff0c\u7136\u540e\u901a\u8fc7\u4e00\u4e2aaccumulator\u53d8\u91cf\u6765\u8bb0\u5f55tl.dot(a, b)\u7684\u7ed3\u679c\uff0cmask\u7684\u4f5c\u7528\u662f\u6765\u5224\u65ad\u8fed\u4ee3\u7684\u8fc7\u7a0b\u4e2d\uff0c\u662f\u5426\u8d8a\u754c\uff0c\u5982\u679c\u8d85\u8fc7\u4e86\u754c\u9650\u7684\u8303\u56f4\uff0c\u5c31\u5c06\u5bf9\u5e94\u7684block\u7f6e\u4e3a0\u3002\u6700\u7ec8\u518d\u5c06\u7ed3\u679c\u6309\u4f4d\u5199\u4f1a\u5230\u5bf9\u5e94\u7684c\u77e9\u9635\u5219\u5b8c\u6210\u4e86\u5bf9\u5e94\u7684\u64cd\u4f5c\u3002"}),"\n",(0,o.jsx)(t.h2,{id:"triton\u7684\u81ea\u52a8\u8c03\u4f18",children:"Triton\u7684\u81ea\u52a8\u8c03\u4f18"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:"@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_M': 8}, num_stages=3, num_warps=8),\n        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\n        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\n    ],\n    key=['M', 'N', 'K'],\n)\n"})}),"\n",(0,o.jsx)(t.p,{children:"\u6211\u4eec\u53bb\u8c03\u6574\u5bf9\u5e94\u7684\u8c03\u4f18\u7a7a\u95f4"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:"@triton.autotune(\n    configs=[ \n        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\n    ],\n    key=['M', 'N', 'K'],\n)\n"})})]})}function d(n={}){const{wrapper:t}={...(0,r.a)(),...n.components};return t?(0,o.jsx)(t,{...n,children:(0,o.jsx)(l,{...n})}):l(n)}},4234:(n,t,e)=>{e.d(t,{Z:()=>o});const o=e.p+"assets/images/image-de3a2d42cda57e442e1a42b3fa335bc1.png"},1151:(n,t,e)=>{e.d(t,{Z:()=>a,a:()=>s});var o=e(7294);const r={},i=o.createContext(r);function s(n){const t=o.useContext(i);return o.useMemo((function(){return"function"==typeof n?n(t):{...t,...n}}),[t,n])}function a(n){let t;return t=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:s(n.components),o.createElement(i.Provider,{value:t},n.children)}}}]);